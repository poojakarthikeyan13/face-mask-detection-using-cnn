{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Final code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojakarthikeyan13/face-mask-detection-using-cnn/blob/master/face%20mask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avq02C88iZZo"
      },
      "source": [
        "# Function to setup the directories we'll be storing our images\n",
        "def makedir(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        return None\n",
        "    else:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDaq6ugGiZZs"
      },
      "source": [
        "## Let's use OpenCV to Build our own object Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZayN7v7iZZs"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "i=0\n",
        "image_count = 0\n",
        "    \n",
        "while i < 9:\n",
        "\n",
        "    ret, frame = cap.read()\n",
        "    frame = cv2.flip(frame, 1)\n",
        "\n",
        "    #define region of interest\n",
        "    roi = frame[100:400, 320:620]\n",
        "    cv2.imshow('roi', roi)\n",
        "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "    roi = cv2.resize(roi, (28, 28), interpolation = cv2.INTER_AREA)\n",
        "\n",
        "    cv2.imshow('roi sacled and gray', roi)\n",
        "    copy = frame.copy()\n",
        "    cv2.rectangle(copy, (320, 100), (620, 400), (255,0,0), 5)\n",
        "    \n",
        "    if i == 0:\n",
        "        image_count = 0\n",
        "        cv2.putText(copy, \"Press Enter to Record 1st object\", (100 , 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
        "    if i == 1:\n",
        "        image_count+=1\n",
        "        cv2.putText(copy, \"Recording 1st object - Train_Dataset\", (100 , 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
        "        cv2.putText(copy, str(image_count), (400 , 400), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
        "        gesture_one = './mask/train/0/'\n",
        "        makedir(gesture_one)\n",
        "        cv2.imwrite(gesture_one + str(image_count) + \".jpg\", roi)\n",
        "    if i == 2:\n",
        "        image_count+=1\n",
        "        cv2.putText(copy, \"Recording 1st object - Test_Dataset\", (100 , 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
        "        cv2.putText(copy, str(image_count), (400 , 400), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
        "        gesture_one = './mask/test/0/'\n",
        "        makedir(gesture_one)\n",
        "        cv2.imwrite(gesture_one + str(image_count) + \".jpg\", roi)\n",
        "    if i == 3:\n",
        "        cv2.putText(copy, \"Press Enter to Record 2st object\", (100 , 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
        "    if i == 4:\n",
        "        image_count+=1\n",
        "        cv2.putText(copy, \"Recording 2nd object - Train_Dataset\", (100 , 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
        "        cv2.putText(copy, str(image_count), (400 , 400), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
        "        gesture_two = './mask/train/1/'\n",
        "        makedir(gesture_two)\n",
        "        cv2.imwrite(gesture_two + str(image_count) + \".jpg\", roi)\n",
        "    if i == 5:\n",
        "        image_count+=1\n",
        "        cv2.putText(copy, \"Recording 2nd object - Test_Dataset\", (100 , 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
        "        cv2.putText(copy, str(image_count), (400 , 400), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
        "        gesture_two = './mask/test/1/'\n",
        "        makedir(gesture_two)\n",
        "        cv2.imwrite(gesture_two + str(image_count) + \".jpg\", roi)\n",
        "    if i == 6:\n",
        "        cv2.putText(copy, \"Press Enter to Record 3st object\", (100 , 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
        "    if i == 7:\n",
        "        image_count+=1\n",
        "        cv2.putText(copy, \"Recording 3rd object - Train_Dataset\", (100 , 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
        "        cv2.putText(copy, str(image_count), (400 , 400), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
        "        gesture_two = './mask/train/2/'\n",
        "        makedir(gesture_two)\n",
        "        cv2.imwrite(gesture_two + str(image_count) + \".jpg\", roi)\n",
        "    if i == 8:\n",
        "        image_count+=1\n",
        "        cv2.putText(copy, \"Recording 3rd object - Test_Dataset\", (100 , 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
        "        cv2.putText(copy, str(image_count), (400 , 400), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
        "        gesture_two = './mask/test/2/'\n",
        "        makedir(gesture_two)\n",
        "        cv2.imwrite(gesture_two + str(image_count) + \".jpg\", roi)\n",
        "    if i == 9:\n",
        "        cv2.putText(copy, \"Hit Enter to Exit\", (100 , 100), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
        "    cv2.imshow('frame', copy)    \n",
        "\n",
        "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
        "        image_count = 0\n",
        "        i+=1\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU8-dT8fiZZv"
      },
      "source": [
        "## Let's use Keras's Data Augmentation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vPirZcNiZZv"
      },
      "source": [
        "import tensorflow.keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "num_classes = 2\n",
        "img_rows, img_cols = 28, 28\n",
        "batch_size = 32\n",
        "\n",
        "train_data_dir = './mask/train'\n",
        "validation_data_dir = './mask/test'\n",
        "\n",
        "# Let's use some data augmentaiton \n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=30,\n",
        "      width_shift_range=0.3,\n",
        "      height_shift_range=0.3,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        " \n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        color_mode = 'grayscale',\n",
        "        class_mode='binary')\n",
        " \n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        color_mode = 'grayscale',\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NciIAN3miZZy"
      },
      "source": [
        "### Creating our Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25bDtSqjiZZy"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=(3,3), activation = 'relu', input_shape=(28,28,1) ))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(0.20))\n",
        "\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss9ROftriZZ0"
      },
      "source": [
        "### Training our Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AfnmC6siZZ1"
      },
      "source": [
        "# We use a very small learning rate \n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'rmsprop',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "nb_train_samples = 1492\n",
        "nb_validation_samples = 554 \n",
        "epochs = 120\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = nb_train_samples // batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = nb_validation_samples // batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP5R9Wd6iZZ3"
      },
      "source": [
        "# Save our Model\n",
        "model.save(\"Mask.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CghqrwDGiZZ6"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "classifier = load_model('Mask.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtusr3RLiZZ8"
      },
      "source": [
        "# Create function to match label to letter\n",
        "def getLetter(result):\n",
        "    classLabels = { 0: 'Without Mask',\n",
        "                    1: 'With Mask',\n",
        "                    }\n",
        "    try:\n",
        "        res = int(result)\n",
        "        return classLabels[res]\n",
        "    except:\n",
        "        return \"Error\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXG2u-nbiZZ-"
      },
      "source": [
        "## Now let's test the model we just built!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c89Ud8x_iZZ_"
      },
      "source": [
        "import cv2\n",
        "cap = cv2.VideoCapture(1)\n",
        "\n",
        "while True:\n",
        "\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    ##############################\n",
        "    frame=cv2.flip(frame, 1)\n",
        "\n",
        "    #define region of interest\n",
        "    roi = frame[100:400, 320:620]\n",
        "    cv2.imshow('roi', roi)\n",
        "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "    roi = cv2.resize(roi, (28, 28), interpolation = cv2.INTER_AREA)\n",
        "    \n",
        "    cv2.imshow('roi scaled and gray', roi)\n",
        "    copy = frame.copy()\n",
        "    cv2.rectangle(copy, (320, 100), (620, 400), (255,0,0), 5)\n",
        "    \n",
        "    roi = roi.reshape(1,28,28,1) \n",
        "    roi = roi/255\n",
        "    result = (classifier.predict_classes(roi, 1, verbose = 0)[0])\n",
        "    #result= str(result)\n",
        "    cv2.putText(copy, getLetter(result), (300 , 100), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 255, 0), 2)\n",
        "    cv2.imshow('frame', copy)\n",
        "    print(result)\n",
        "    \n",
        "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
        "        break\n",
        "        \n",
        "cap.release()\n",
        "cv2.destroyAllWindows() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G5889IFiZaB"
      },
      "source": [
        "cap.release()\n",
        "cv2.destroyAllWindows() "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}